{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary components \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D\n",
    "from matplotlib import pyplot\n",
    "from math import sqrt\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SARS and COVID csv files\n",
    "# Only import 'date' and 'cumulative_cases' columns\n",
    "canada_sars = pd.read_csv('./data/sars_canada.csv', header = 0, index_col = 0, usecols=['date', 'cumulative_cases'])\n",
    "canada_covid = pd.read_csv('./data/covid_canada.csv', header = 0, index_col = 0, usecols=['date', 'cumulative_cases'])\n",
    "\n",
    "# Given input data and how many training data it would be used,\n",
    "# Split the input data into train and test data\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# Convert into data\n",
    "data_train = canada_sars.values\n",
    "data_test = canada_covid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a few functions that is needed\n",
    "# These functions are used for RMSE calculation as well as walk-forward validation\n",
    "\n",
    "# Shifting data to in order for an 'one-step forecast'\n",
    "def shift_data(data, n_in = 1, n_out = 1):\n",
    "    dataframe = pd.DataFrame(data)\n",
    "    col = list()\n",
    "\n",
    "    # Separate into two col, with one that is shifted forward\n",
    "    for i in range(n_in, 0, -1):\n",
    "        col.append(dataframe.shift(i))\n",
    "\n",
    "    for i in range(0, n_out):\n",
    "        col.append(dataframe.shift(-i))\n",
    "\n",
    "    # Brings all result together and drop rows with NaN\n",
    "    result = pd.concat(col, axis=1)\n",
    "    result.dropna(inplace=True)\n",
    "\n",
    "    return result.values\n",
    "\n",
    "# Returns the RMSE (Root Mean Square Error) given the actual and predicted value\n",
    "def calculate_error(actual, predicted):\n",
    "\tprint('Actual: ' + f'{actual[len(actual) - 1][0]}')\n",
    "\tprint('Predicted: %.0f' % (predicted[len(predicted) - 1][0]))\n",
    "\n",
    "\tpyplot.plot(actual, label='Actual')\n",
    "\tpyplot.plot(predicted, label='Predicted')\n",
    "\tpyplot.legend()\n",
    "\tpyplot.show()\n",
    "\n",
    "\treturn sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# This function does walk forward validation\n",
    "# This is when the modal makes a one step forecast for each observation\n",
    "def walk_forward_validation(test, train, config):\n",
    "    prediction = list()\n",
    "\n",
    "    # Fit model\n",
    "    model = fit_model(train, config)\n",
    "\n",
    "    # Set history\n",
    "    history = [x for x in train]\n",
    "\n",
    "    for i in range(len(test)):\n",
    "        # Fit model and make a forecast for the history\n",
    "        y_hat = predict_model(model, history, config)\n",
    "\n",
    "        # Stores the forecast into a list\n",
    "        prediction.append(y_hat)\n",
    "        history.append(test[i])\n",
    "    \n",
    "    # Estimate error\n",
    "    error = calculate_error(test, prediction)\n",
    "    print('Error: ' + '%.3f' % error)\n",
    "\n",
    "    return error\n",
    "\n",
    "# Repeated evaluation\n",
    "def repeat_evaluation(test, train, config, n_repeats):\n",
    "    score_list = list()\n",
    "\n",
    "    for i in range(n_repeats):\n",
    "        print('\\nIteration: %.0f' % (i + 1))\n",
    "        score_list.append(walk_forward_validation(test, train, config))\n",
    "\n",
    "    return score_list\n",
    "\n",
    "# Summarize model\n",
    "def summarize(name, score_list):\n",
    "    score_m, score_std = mean(score_list), std(score_list)\n",
    "    print('\\n%s: %.3f RMSE (+/- %.3f)' % (name, score_m, score_std))\n",
    "\n",
    "    # Create box and whisker plot\n",
    "    pyplot.boxplot(score_list)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Convolutional Neural Network model using the following configuration\n",
    "# n_input: The number of observations to use\n",
    "# n_filters: The number of parallel filters\n",
    "# n_kernel: The number of steps in each in/out sequence\n",
    "# n_epochs: The number of times to expose the model\n",
    "# n_batch: The number of samples within an epoch after the weights are updated\n",
    "\n",
    "# Define and then fit the model\n",
    "# Given the training data, and configuration, this function fits a model\n",
    "def fit_model(train, config):\n",
    "    n_input, n_filters, n_kernel, n_epochs, n_batch = config\n",
    "\n",
    "    # Separate training data in to X and y\n",
    "    data = shift_data(train, n_in=n_input)\n",
    "    train_x, train_y = data[:, :-1], data[:, -1]\n",
    "    train_x = train_x.reshape((train_x.shape[0], train_x.shape[1], 1))\n",
    "\n",
    "    # Define model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=n_filters, kernel_size=n_kernel, activation='relu', input_shape=(n_input, 1)))\n",
    "    model.add(Conv1D(filters=n_filters, kernel_size=n_kernel, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Predict the model\n",
    "# Given a model, the history, and configuration, this function predicts a model\n",
    "def predict_model(model, history, config):\n",
    "    n_input, _, _, _, _ = config\n",
    "\n",
    "    # Prepare data\n",
    "    x_input = array(history[-n_input:]).reshape((1, n_input, 1))\n",
    "\n",
    "    # Predict model\n",
    "    y_hat = model.predict(x_input, verbose=0)\n",
    "\n",
    "    return y_hat[0]\n",
    "\n",
    "# After defining the two functions needed to fit and predict the model, define the configuration\n",
    "config = [14, 256, 3, 100, 1]\n",
    "\n",
    "# Create and fit model\n",
    "# Error is calculate throughout the entire prediction period\n",
    "score_list = repeat_evaluation(data_test, data_train, config, 10)\n",
    "summarize('CNN', score_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit",
   "name": "python36764bit7169f5127d904057b5023f7ae9a2b18c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}